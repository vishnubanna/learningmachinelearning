{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myOwnMultiPercptronNuralNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnubanna/learningmachinelearning/blob/master/myOwnMultiPercptronNuralNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw4MmLMqmI6J",
        "colab_type": "text"
      },
      "source": [
        "We use numpy to use arrays as matricies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du_I1idyl5Jv",
        "colab_type": "code",
        "outputId": "703ba0c1-5f79-47e1-a1e4-87031fa8824a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.zeros([3,2])\n",
        "#print(a)\n",
        "\n",
        "a[0,0] = 1\n",
        "a[0,1] = 2\n",
        "a[1,0] = 9\n",
        "a[2,1] = 12\n",
        "\n",
        "print(a)\n",
        "\n",
        "print(a[0,1])\n",
        "v = a[1,0]\n",
        "\n",
        "print(v)\n",
        "#print(a[0,2])\n",
        "\n",
        "a = np.random.rand(3,3) #--> matrix of 3,3 size of random numbers btwn 0 and 1\n",
        "print(a)\n",
        "\n",
        "# a = a - 1# subtracts all numbers by 1\n",
        "# print(a)\n",
        "\n",
        "# a = np.random.rand(3,3) - 0.5 #--> matrix of 3,3 size or random numbers - o.5 shifts the wieghts to be both positive and negative  \n",
        "# print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.  2.]\n",
            " [ 9.  0.]\n",
            " [ 0. 12.]]\n",
            "2.0\n",
            "9.0\n",
            "[[0.958192   0.86802075 0.52242633]\n",
            " [0.79510892 0.70358445 0.6894447 ]\n",
            " [0.94619917 0.19987554 0.72639138]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtUbamytmfK6",
        "colab_type": "text"
      },
      "source": [
        "matplotlib can be used to plot arrays and the info in the arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US-mrEC1oAZA",
        "colab_type": "code",
        "outputId": "737f2abc-bbfe-466d-fa4c-84d9cc5b5097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "a = np.random.rand(3,3) #--> matrix of 3,3 size of random numbers btwn 0 and 1\n",
        "print(a)\n",
        "plt.imshow(a, interpolation=\"nearest\") #interpolation = nearest tell ths computer not to blend color "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.37774628 0.31732006 0.37887997]\n",
            " [0.83505542 0.00602516 0.9019163 ]\n",
            " [0.53712943 0.99058312 0.80694161]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5faf991eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUuzi5H8qA6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import *\n",
        "import scipy.special \n",
        "\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, inputs, hiddens, outputs, layers, learning_rate):\n",
        "        #init the network\n",
        "        self.inodes = inputs \n",
        "        self.hnodes = hiddens\n",
        "        self.onodes = outputs\n",
        "        self.layers = layers\n",
        "        #self.sigmoid = lambda x: 1/(1+exp(-x))\n",
        "        self.sigmoid = lambda x: scipy.special.expit(x)\n",
        "        self.MSE = lambda x, label: (label - x)**2\n",
        "        \n",
        "        self.lr = learning_rate\n",
        "        \n",
        "#         self.wih = np.random.rand(self.hnodes, self.inodes) - 0.5\n",
        "#         self.who = np.random.rand(self.onodes, self.hnodes) - 0.5\n",
        "        \n",
        "        self.wih = np.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
        "        self.who = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
        "        pass\n",
        "    \n",
        "\n",
        "    def train(self, train_set, target_set):\n",
        "        #convert input and target list into 2d arrays\n",
        "        inputs = np.array(train_set, ndmin = 2).T \n",
        "        #print(inputs)\n",
        "        targets = np.array(target_set, ndmin = 2).T #ndmin = minimum number of dimentions in the new array\n",
        "        #.T = transpose\n",
        "        ih_wdot = np.dot(self.wih, inputs)\n",
        "        \n",
        "        ih_output = np.array([self.sigmoid(value) for value in ih_wdot ])\n",
        "        #gives you the anser from the output nodes after being given the input\n",
        "        #print(ih_wdot)\n",
        "        #print(ih_output)\n",
        "        \n",
        "        ho_wdot = np.dot(self.who, ih_output)\n",
        "        ho_output = np.array([self.sigmoid(value) for value in ho_wdot ])\n",
        "        #print(ho_wdot)\n",
        "        #print(ho_output)\n",
        "\n",
        "        op_error = (targets - ho_output)\n",
        "        error_ho =  np.dot(self.who.T, op_error)\n",
        "        #error_ih =  np.dot(self.wih.T, error_ho)\n",
        "        \n",
        "        dw_ho = self.lr * np.dot(op_error * ho_output * (1 - ho_output), ih_output.T)\n",
        "        dw_ih = self.lr * np.dot(error_ho * ih_output * (1 - ih_output), inputs.T)\n",
        "        #train:refine the wieghts after being given a traing set example\n",
        "        \n",
        "        self.who = self.who + dw_ho\n",
        "        self.wih = self.wih + dw_ih\n",
        "        pass\n",
        "    \n",
        "    def query(self, inputs):\n",
        "        \n",
        "        inputs = np.array(inputs, ndmin = 2).T\n",
        "        ih_wdot = np.dot(self.wih, inputs)\n",
        "        \n",
        "        ih_output = np.array([self.sigmoid(value) for value in ih_wdot ])\n",
        "        #gives you the anser from the output nodes after being given the input\n",
        "        print(ih_wdot)\n",
        "        print(ih_output)\n",
        "        \n",
        "        ho_wdot = np.dot(self.who, ih_output)\n",
        "        ho_output = np.array([self.sigmoid(value) for value in ho_wdot ])\n",
        "        print(ho_wdot)\n",
        "        print(ho_output)\n",
        "        return (ho_output)\n",
        "    \n",
        "    def printe(self):\n",
        "        print(self.wih)\n",
        "        print(self.who)\n",
        "        pass\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4bDUV09bwpN",
        "colab_type": "code",
        "outputId": "344bf1d5-eff1-4a72-9866-6b3d25a7d1b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "input_size = 784\n",
        "n = NeuralNetwork(input_size, 1024, 10, 1, 0.3)\n",
        "n.printe()\n",
        "\n",
        "input1 = np.random.rand(1,input_size)\n",
        "input2 = np.random.rand(2,input_size)\n",
        "output = np.random.rand(2,10)\n",
        "\n",
        "#output = \n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.00779247 -0.02649462  0.0562146  ... -0.03632979 -0.0134599\n",
            "  -0.04440122]\n",
            " [-0.00629312  0.00743644  0.02550294 ... -0.026091    0.04975518\n",
            "   0.03964759]\n",
            " [ 0.04275577 -0.01867051 -0.02402109 ... -0.03911389  0.05625861\n",
            "   0.03433683]\n",
            " ...\n",
            " [-0.02545471 -0.05315346  0.04555432 ... -0.03769633 -0.00914666\n",
            "   0.01925184]\n",
            " [ 0.00761537  0.08765583  0.05661441 ...  0.02779328 -0.13035529\n",
            "  -0.05703051]\n",
            " [ 0.03980453  0.03279524 -0.00823044 ... -0.02172625  0.01724622\n",
            "   0.01069076]]\n",
            "[[-1.45230653e-02 -3.34720139e-03  1.79613733e-02 ... -2.78282523e-02\n",
            "   1.94598305e-03 -8.11855005e-02]\n",
            " [ 1.54344437e-02  4.86242374e-02 -7.62310046e-03 ... -7.80390048e-03\n",
            "   7.93490872e-03  2.18175752e-02]\n",
            " [ 2.66471973e-02  1.58199393e-02  1.46713810e-02 ... -1.12919815e-02\n",
            "   2.17047198e-03  7.50147010e-03]\n",
            " ...\n",
            " [-2.70495365e-02 -8.42976983e-02 -5.13881296e-03 ...  6.11041740e-02\n",
            "  -4.11733944e-02  1.74944305e-02]\n",
            " [ 3.09612635e-02  2.05783771e-02  5.43333195e-02 ...  3.41314245e-02\n",
            "   4.57716959e-03  3.55277489e-02]\n",
            " [ 1.59584148e-02 -1.75123508e-02 -1.95741248e-02 ...  1.89029893e-02\n",
            "  -8.84517445e-05 -5.12481493e-02]]\n",
            "[[0.98045479 0.5071202  0.96422322 0.98332078 0.85611933 0.93967986\n",
            "  0.94314135 0.8335926  0.14692622 0.4553075 ]\n",
            " [0.31284116 0.1136701  0.70909766 0.31371183 0.7766827  0.15267442\n",
            "  0.79679669 0.77403652 0.12707946 0.09896239]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2AEVwlgpwAu",
        "colab_type": "code",
        "outputId": "ecc0b8c6-076e-43e8-a6f6-390f7eebe2ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4437
        }
      },
      "source": [
        "#input = [[0.37298079, 0.14116122, 0.85006551, 0.13425626, 0.62141436, 0.22597164, 0.06044884, 0.29831745, 0.8687268, 0.11688487]]\n",
        "#print(input1)\n",
        "#print('\\n')\n",
        "#n.query(input1)\n",
        "import time\n",
        "for i in range(10):\n",
        "    n.train(input2, output)\n",
        "    time.sleep(1)\n",
        "    n.printe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.00874215 -0.02782509  0.05889863 ... -0.03538429 -0.01239021\n",
            "  -0.04275313]\n",
            " [-0.0064055   0.00039037  0.01613468 ... -0.03159956  0.04626928\n",
            "   0.03044047]\n",
            " [ 0.04309194 -0.02551028 -0.03525052 ... -0.0454134   0.05204614\n",
            "   0.02377521]\n",
            " ...\n",
            " [-0.02624012 -0.06486676  0.03285152 ... -0.04557353 -0.01382756\n",
            "   0.00612943]\n",
            " [ 0.00697767  0.07994675  0.04883343 ...  0.02286725 -0.13321122\n",
            "  -0.0652264 ]\n",
            " [ 0.03544219  0.02701883  0.00456967 ... -0.01710976  0.02233554\n",
            "   0.0187185 ]]\n",
            "[[-0.01561629 -0.00027526  0.02961729 ... -0.00616769  0.01590732\n",
            "  -0.09220463]\n",
            " [ 0.00309418  0.03562906 -0.01747539 ... -0.02113627  0.00095868\n",
            "  -0.00447384]\n",
            " [ 0.03110685  0.02976536  0.0334956  ...  0.02064183  0.02166779\n",
            "   0.01037121]\n",
            " ...\n",
            " [-0.01836664 -0.06949955  0.01225971 ...  0.0896721  -0.02440906\n",
            "   0.03660806]\n",
            " [ 0.02174453  0.00772128  0.04107343 ...  0.01306769 -0.00857759\n",
            "   0.01605187]\n",
            " [ 0.00569679 -0.03130494 -0.03362595 ... -0.00253815 -0.01088086\n",
            "  -0.07779429]]\n",
            "[[-0.00874214 -0.02782506  0.05889863 ... -0.03538429 -0.01239021\n",
            "  -0.04275312]\n",
            " [-0.0064055   0.00039036  0.01613468 ... -0.03159956  0.04626928\n",
            "   0.03044047]\n",
            " [ 0.04309194 -0.02551028 -0.03525052 ... -0.0454134   0.05204614\n",
            "   0.02377521]\n",
            " ...\n",
            " [-0.02624012 -0.06486677  0.03285152 ... -0.04557354 -0.01382756\n",
            "   0.00612943]\n",
            " [ 0.00697766  0.07994674  0.04883343 ...  0.02286725 -0.13321122\n",
            "  -0.0652264 ]\n",
            " [ 0.03544219  0.02701883  0.00456968 ... -0.01710976  0.02233554\n",
            "   0.01871851]]\n",
            "[[-0.01561628 -0.00027525  0.02961729 ... -0.0061677   0.01590732\n",
            "  -0.09220458]\n",
            " [ 0.00309418  0.03562906 -0.01747539 ... -0.02113627  0.00095868\n",
            "  -0.00447384]\n",
            " [ 0.03110685  0.02976536  0.0334956  ...  0.02064183  0.02166778\n",
            "   0.01037124]\n",
            " ...\n",
            " [-0.01836665 -0.06949955  0.01225971 ...  0.08967209 -0.02440906\n",
            "   0.03660806]\n",
            " [ 0.02174453  0.00772128  0.04107343 ...  0.0130677  -0.00857758\n",
            "   0.01605188]\n",
            " [ 0.00569679 -0.03130494 -0.03362595 ... -0.00253815 -0.01088086\n",
            "  -0.07779429]]\n",
            "[[-0.00874213 -0.02782504  0.05889862 ... -0.03538429 -0.01239021\n",
            "  -0.04275312]\n",
            " [-0.00640551  0.00039035  0.01613468 ... -0.03159956  0.04626928\n",
            "   0.03044047]\n",
            " [ 0.04309194 -0.02551029 -0.03525052 ... -0.0454134   0.05204614\n",
            "   0.02377521]\n",
            " ...\n",
            " [-0.02624012 -0.06486678  0.03285152 ... -0.04557354 -0.01382756\n",
            "   0.00612942]\n",
            " [ 0.00697766  0.07994673  0.04883343 ...  0.02286724 -0.13321122\n",
            "  -0.06522641]\n",
            " [ 0.03544219  0.02701883  0.00456968 ... -0.01710975  0.02233554\n",
            "   0.01871851]]\n",
            "[[-0.01561626 -0.00027525  0.02961729 ... -0.0061677   0.01590732\n",
            "  -0.09220453]\n",
            " [ 0.00309418  0.03562906 -0.01747539 ... -0.02113627  0.00095868\n",
            "  -0.00447384]\n",
            " [ 0.03110686  0.02976536  0.0334956  ...  0.02064183  0.02166778\n",
            "   0.01037127]\n",
            " ...\n",
            " [-0.01836665 -0.06949955  0.0122597  ...  0.08967209 -0.02440906\n",
            "   0.03660806]\n",
            " [ 0.02174454  0.00772129  0.04107344 ...  0.0130677  -0.00857758\n",
            "   0.01605188]\n",
            " [ 0.00569679 -0.03130494 -0.03362595 ... -0.00253815 -0.01088087\n",
            "  -0.07779429]]\n",
            "[[-0.00874213 -0.02782502  0.05889862 ... -0.03538428 -0.01239021\n",
            "  -0.04275311]\n",
            " [-0.00640551  0.00039034  0.01613468 ... -0.03159957  0.04626928\n",
            "   0.03044047]\n",
            " [ 0.04309193 -0.02551029 -0.03525052 ... -0.0454134   0.05204614\n",
            "   0.0237752 ]\n",
            " ...\n",
            " [-0.02624013 -0.06486679  0.03285152 ... -0.04557354 -0.01382756\n",
            "   0.00612942]\n",
            " [ 0.00697766  0.07994672  0.04883343 ...  0.02286724 -0.13321122\n",
            "  -0.06522641]\n",
            " [ 0.03544219  0.02701883  0.00456969 ... -0.01710975  0.02233554\n",
            "   0.01871852]]\n",
            "[[-0.01561624 -0.00027525  0.02961729 ... -0.0061677   0.01590732\n",
            "  -0.09220447]\n",
            " [ 0.00309418  0.03562906 -0.01747539 ... -0.02113627  0.00095868\n",
            "  -0.00447384]\n",
            " [ 0.03110686  0.02976536  0.03349559 ...  0.02064183  0.02166778\n",
            "   0.0103713 ]\n",
            " ...\n",
            " [-0.01836666 -0.06949956  0.0122597  ...  0.08967209 -0.02440907\n",
            "   0.03660806]\n",
            " [ 0.02174455  0.00772129  0.04107344 ...  0.0130677  -0.00857758\n",
            "   0.01605188]\n",
            " [ 0.00569678 -0.03130494 -0.03362595 ... -0.00253815 -0.01088087\n",
            "  -0.07779429]]\n",
            "[[-0.00874212 -0.027825    0.05889862 ... -0.03538428 -0.01239021\n",
            "  -0.04275311]\n",
            " [-0.00640551  0.00039033  0.01613468 ... -0.03159957  0.04626929\n",
            "   0.03044047]\n",
            " [ 0.04309193 -0.02551029 -0.03525052 ... -0.0454134   0.05204614\n",
            "   0.0237752 ]\n",
            " ...\n",
            " [-0.02624013 -0.0648668   0.03285152 ... -0.04557354 -0.01382756\n",
            "   0.00612942]\n",
            " [ 0.00697766  0.07994671  0.04883342 ...  0.02286724 -0.13321122\n",
            "  -0.06522641]\n",
            " [ 0.03544219  0.02701884  0.0045697  ... -0.01710975  0.02233555\n",
            "   0.01871852]]\n",
            "[[-0.01561623 -0.00027525  0.02961729 ... -0.0061677   0.01590732\n",
            "  -0.09220442]\n",
            " [ 0.00309418  0.03562906 -0.01747539 ... -0.02113627  0.00095868\n",
            "  -0.00447384]\n",
            " [ 0.03110687  0.02976536  0.03349559 ...  0.02064182  0.02166778\n",
            "   0.01037133]\n",
            " ...\n",
            " [-0.01836666 -0.06949956  0.0122597  ...  0.08967209 -0.02440907\n",
            "   0.03660806]\n",
            " [ 0.02174456  0.00772129  0.04107344 ...  0.01306771 -0.00857757\n",
            "   0.01605189]\n",
            " [ 0.00569678 -0.03130494 -0.03362595 ... -0.00253816 -0.01088087\n",
            "  -0.07779429]]\n",
            "[[-0.00874211 -0.02782497  0.05889861 ... -0.03538428 -0.01239022\n",
            "  -0.04275311]\n",
            " [-0.00640551  0.00039033  0.01613468 ... -0.03159957  0.04626929\n",
            "   0.03044046]\n",
            " [ 0.04309193 -0.0255103  -0.03525052 ... -0.0454134   0.05204614\n",
            "   0.0237752 ]\n",
            " ...\n",
            " [-0.02624013 -0.06486681  0.03285152 ... -0.04557354 -0.01382756\n",
            "   0.00612942]\n",
            " [ 0.00697765  0.0799467   0.04883342 ...  0.02286724 -0.13321122\n",
            "  -0.06522642]\n",
            " [ 0.03544219  0.02701884  0.0045697  ... -0.01710975  0.02233555\n",
            "   0.01871853]]\n",
            "[[-0.01561621 -0.00027524  0.02961729 ... -0.0061677   0.01590732\n",
            "  -0.09220437]\n",
            " [ 0.00309418  0.03562906 -0.01747539 ... -0.02113627  0.00095868\n",
            "  -0.00447385]\n",
            " [ 0.03110687  0.02976536  0.03349559 ...  0.02064182  0.02166777\n",
            "   0.01037136]\n",
            " ...\n",
            " [-0.01836667 -0.06949956  0.01225969 ...  0.08967208 -0.02440907\n",
            "   0.03660806]\n",
            " [ 0.02174457  0.00772129  0.04107345 ...  0.01306771 -0.00857757\n",
            "   0.01605189]\n",
            " [ 0.00569678 -0.03130494 -0.03362595 ... -0.00253816 -0.01088087\n",
            "  -0.07779429]]\n",
            "[[-0.0087421  -0.02782495  0.05889861 ... -0.03538428 -0.01239022\n",
            "  -0.0427531 ]\n",
            " [-0.00640552  0.00039032  0.01613468 ... -0.03159957  0.04626929\n",
            "   0.03044046]\n",
            " [ 0.04309193 -0.0255103  -0.03525052 ... -0.04541341  0.05204614\n",
            "   0.0237752 ]\n",
            " ...\n",
            " [-0.02624013 -0.06486682  0.03285152 ... -0.04557354 -0.01382756\n",
            "   0.00612941]\n",
            " [ 0.00697765  0.07994669  0.04883342 ...  0.02286724 -0.13321122\n",
            "  -0.06522642]\n",
            " [ 0.03544219  0.02701884  0.00456971 ... -0.01710974  0.02233555\n",
            "   0.01871853]]\n",
            "[[-0.0156162  -0.00027524  0.02961729 ... -0.0061677   0.01590732\n",
            "  -0.09220432]\n",
            " [ 0.00309418  0.03562906 -0.01747539 ... -0.02113627  0.00095868\n",
            "  -0.00447385]\n",
            " [ 0.03110687  0.02976536  0.03349559 ...  0.02064182  0.02166777\n",
            "   0.01037139]\n",
            " ...\n",
            " [-0.01836668 -0.06949956  0.01225969 ...  0.08967208 -0.02440908\n",
            "   0.03660807]\n",
            " [ 0.02174458  0.0077213   0.04107345 ...  0.01306771 -0.00857756\n",
            "   0.01605189]\n",
            " [ 0.00569677 -0.03130495 -0.03362596 ... -0.00253816 -0.01088087\n",
            "  -0.07779428]]\n",
            "[[-0.0087421  -0.02782493  0.05889861 ... -0.03538427 -0.01239022\n",
            "  -0.0427531 ]\n",
            " [-0.00640552  0.00039031  0.01613468 ... -0.03159957  0.04626929\n",
            "   0.03044046]\n",
            " [ 0.04309193 -0.0255103  -0.03525052 ... -0.04541341  0.05204614\n",
            "   0.0237752 ]\n",
            " ...\n",
            " [-0.02624014 -0.06486683  0.03285152 ... -0.04557355 -0.01382756\n",
            "   0.00612941]\n",
            " [ 0.00697765  0.07994668  0.04883342 ...  0.02286723 -0.13321122\n",
            "  -0.06522642]\n",
            " [ 0.03544219  0.02701885  0.00456971 ... -0.01710974  0.02233555\n",
            "   0.01871854]]\n",
            "[[-0.01561618 -0.00027524  0.02961729 ... -0.0061677   0.01590732\n",
            "  -0.09220427]\n",
            " [ 0.00309418  0.03562906 -0.01747539 ... -0.02113627  0.00095868\n",
            "  -0.00447385]\n",
            " [ 0.03110688  0.02976536  0.03349558 ...  0.02064182  0.02166777\n",
            "   0.01037142]\n",
            " ...\n",
            " [-0.01836668 -0.06949956  0.01225969 ...  0.08967208 -0.02440908\n",
            "   0.03660807]\n",
            " [ 0.02174458  0.0077213   0.04107345 ...  0.01306771 -0.00857756\n",
            "   0.0160519 ]\n",
            " [ 0.00569677 -0.03130495 -0.03362596 ... -0.00253816 -0.01088087\n",
            "  -0.07779428]]\n",
            "[[-0.00874209 -0.02782491  0.0588986  ... -0.03538427 -0.01239022\n",
            "  -0.0427531 ]\n",
            " [-0.00640552  0.0003903   0.01613469 ... -0.03159957  0.04626929\n",
            "   0.03044046]\n",
            " [ 0.04309193 -0.02551031 -0.03525052 ... -0.04541341  0.05204614\n",
            "   0.0237752 ]\n",
            " ...\n",
            " [-0.02624014 -0.06486684  0.03285152 ... -0.04557355 -0.01382756\n",
            "   0.00612941]\n",
            " [ 0.00697764  0.07994667  0.04883342 ...  0.02286723 -0.13321122\n",
            "  -0.06522643]\n",
            " [ 0.03544219  0.02701885  0.00456972 ... -0.01710974  0.02233555\n",
            "   0.01871854]]\n",
            "[[-0.01561617 -0.00027524  0.02961729 ... -0.0061677   0.01590732\n",
            "  -0.09220421]\n",
            " [ 0.00309418  0.03562906 -0.01747539 ... -0.02113627  0.00095868\n",
            "  -0.00447385]\n",
            " [ 0.03110688  0.02976536  0.03349558 ...  0.02064182  0.02166777\n",
            "   0.01037144]\n",
            " ...\n",
            " [-0.01836669 -0.06949957  0.01225969 ...  0.08967208 -0.02440908\n",
            "   0.03660807]\n",
            " [ 0.02174459  0.0077213   0.04107346 ...  0.01306772 -0.00857756\n",
            "   0.0160519 ]\n",
            " [ 0.00569677 -0.03130495 -0.03362596 ... -0.00253816 -0.01088088\n",
            "  -0.07779428]]\n",
            "[[-0.00874208 -0.02782489  0.0588986  ... -0.03538427 -0.01239022\n",
            "  -0.04275309]\n",
            " [-0.00640552  0.00039029  0.01613469 ... -0.03159957  0.04626929\n",
            "   0.03044046]\n",
            " [ 0.04309193 -0.02551031 -0.03525052 ... -0.04541341  0.05204614\n",
            "   0.0237752 ]\n",
            " ...\n",
            " [-0.02624014 -0.06486685  0.03285152 ... -0.04557355 -0.01382756\n",
            "   0.0061294 ]\n",
            " [ 0.00697764  0.07994666  0.04883342 ...  0.02286723 -0.13321122\n",
            "  -0.06522643]\n",
            " [ 0.03544219  0.02701885  0.00456972 ... -0.01710973  0.02233555\n",
            "   0.01871855]]\n",
            "[[-0.01561615 -0.00027523  0.02961729 ... -0.0061677   0.01590732\n",
            "  -0.09220416]\n",
            " [ 0.00309418  0.03562906 -0.01747539 ... -0.02113627  0.00095868\n",
            "  -0.00447385]\n",
            " [ 0.03110688  0.02976536  0.03349558 ...  0.02064181  0.02166776\n",
            "   0.01037147]\n",
            " ...\n",
            " [-0.01836669 -0.06949957  0.01225968 ...  0.08967208 -0.02440909\n",
            "   0.03660807]\n",
            " [ 0.0217446   0.0077213   0.04107346 ...  0.01306772 -0.00857755\n",
            "   0.0160519 ]\n",
            " [ 0.00569677 -0.03130495 -0.03362596 ... -0.00253816 -0.01088088\n",
            "  -0.07779428]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW1T4EMdfQyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork2:\n",
        "    def __init__(self, inputs, outputs, hlayers, learning_rate):\n",
        "        #init the network\n",
        "        self.inodes = inputs \n",
        "        #self.hnodes = hiddens\n",
        "        self.onodes = outputs\n",
        "        self.layers = hlayers\n",
        "        self.layerlen = len(self.layers)\n",
        "        self.weights = []\n",
        "        self.weight_names = []\n",
        "        \n",
        "        self.lr = learning_rate\n",
        "        pass\n",
        "    def initializer(self):\n",
        "        self.layers.insert(0, self.inodes)\n",
        "        self.layerlen = len(self.layers)\n",
        "        self.layers.insert(self.layerlen, self.onodes)\n",
        "        self.layerlen = len(self.layers)\n",
        "        \n",
        "        for i in range(1, self.layerlen):\n",
        "            self.weights.append(np.random.normal(0.0, pow(self.inodes, -0.5), (self.layers[i], self.layers[i-1])))\n",
        "            self.weight_names.append(i)\n",
        "            \n",
        "        print(self.weights)\n",
        "        self.weight_names[0] = 'input -> hidden'\n",
        "        self.weight_names[len(self.weight_names) - 1] = 'hidden -> output'\n",
        "        print(self.weight_names)\n",
        "            \n",
        "        pass\n",
        "    \n",
        "    def printer(self):\n",
        "        print(self.layers)\n",
        "        pass\n",
        "        \n",
        "    def add(self, nodes):\n",
        "        self.layers.append(nodes)\n",
        "        self.hiddenlayers = len(self.layers)\n",
        "        pass\n",
        "    \n",
        "    def train():\n",
        "        #train:refine the wieghts after being given a traing set example\n",
        "        pass\n",
        "    \n",
        "    def query():\n",
        "        #gives you the anser from the output nodes after being given the input\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoI6makJilwt",
        "colab_type": "code",
        "outputId": "bb724e4d-63d0-4a09-bac0-149320dd45c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "n = NeuralNetwork2(3, 10, [3, 3, 3] , 0.3)\n",
        "#n.add(3)\n",
        "n.initializer()\n",
        "n.printer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[-0.44186072, -0.37472376, -0.00085095],\n",
            "       [-0.09829278,  0.10547386, -0.76641091],\n",
            "       [ 0.45316237,  0.18939704, -0.72122867]]), array([[-0.68251844,  0.27646226, -0.40085557],\n",
            "       [ 0.72100157,  1.27828488,  0.55182899],\n",
            "       [ 0.19210237,  0.06018621,  0.65423527]]), array([[-0.93057011, -0.49589857,  1.16061072],\n",
            "       [ 0.39938379, -1.18955813, -0.07374177],\n",
            "       [-0.10490972,  0.76710616,  0.93991383]]), array([[ 1.36102699,  0.57906652, -0.19113083],\n",
            "       [-0.10681543,  0.61640061,  0.13500915],\n",
            "       [-0.53686839, -0.5422375 ,  0.78429126],\n",
            "       [-0.06882307, -0.33175284,  0.00195483],\n",
            "       [-0.20913803, -0.48453924, -0.46552549],\n",
            "       [-0.80801779, -0.60681026, -1.11337207],\n",
            "       [-0.04349056,  0.11637782,  0.02040909],\n",
            "       [ 0.2548964 , -0.25070765,  0.18870933],\n",
            "       [ 0.36185356, -0.52479698, -0.87256182],\n",
            "       [ 0.14193317,  0.45478282, -0.26672984]])]\n",
            "['input -> hidden', 2, 3, 'hidden -> output']\n",
            "[3, 3, 3, 3, 10]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}