{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LocalNet conved.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnubanna/learningmachinelearning/blob/master/LocalNet_conved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1FkR4ekTAV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install tensorflow==2.0.0-beta1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7manFjq-rIHz",
        "colab_type": "code",
        "outputId": "810cd219-6631-4cd4-8e4c-51eb8a0b1f3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "pip install tensorflow-gpu==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-beta1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/53/e18c5e7a2263d3581a979645a185804782e59b8e13f42b9c3c3cfb5bb503/tensorflow_gpu-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (348.9MB)\n",
            "\u001b[K     |████████████████████████████████| 348.9MB 71kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (3.7.1)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow-gpu==2.0.0-beta1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 52.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.33.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.16.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.15.0)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow-gpu==2.0.0-beta1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-beta1) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta1) (2.8.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-gpu-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsd5U4Rk4R0a",
        "colab_type": "code",
        "outputId": "081e21b8-5da9-46e8-c6bf-1cd62fcf55ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!rm *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'sample_data': Is a directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMIs4wCHUV8k",
        "colab_type": "code",
        "outputId": "85d31305-6d87-4e77-9f20-a7143bce70d0",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import files \n",
        "uploads = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-22a97d6b-6777-4d06-9f82-ebcb2ca66b3d\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-22a97d6b-6777-4d06-9f82-ebcb2ca66b3d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cucumber_1.jpg to cucumber_1.jpg\n",
            "Saving cucumber_1.xml to cucumber_1.xml\n",
            "Saving cucumber_2.jpg to cucumber_2.jpg\n",
            "Saving cucumber_2.xml to cucumber_2.xml\n",
            "Saving cucumber_3.jpg to cucumber_3.jpg\n",
            "Saving cucumber_3.xml to cucumber_3.xml\n",
            "Saving cucumber_4.jpg to cucumber_4.jpg\n",
            "Saving cucumber_4.xml to cucumber_4.xml\n",
            "Saving cucumber_5.jpg to cucumber_5.jpg\n",
            "Saving cucumber_5.xml to cucumber_5.xml\n",
            "Saving cucumber_6.jpg to cucumber_6.jpg\n",
            "Saving cucumber_6.xml to cucumber_6.xml\n",
            "Saving cucumber_7.jpg to cucumber_7.jpg\n",
            "Saving cucumber_7.xml to cucumber_7.xml\n",
            "Saving cucumber_8.jpg to cucumber_8.jpg\n",
            "Saving cucumber_8.xml to cucumber_8.xml\n",
            "Saving cucumber_9.jpg to cucumber_9.jpg\n",
            "Saving cucumber_9.xml to cucumber_9.xml\n",
            "Saving cucumber_10.jpg to cucumber_10.jpg\n",
            "Saving cucumber_10.xml to cucumber_10.xml\n",
            "Saving cucumber_11.jpg to cucumber_11.jpg\n",
            "Saving cucumber_11.xml to cucumber_11.xml\n",
            "Saving cucumber_12.jpg to cucumber_12.jpg\n",
            "Saving cucumber_12.xml to cucumber_12.xml\n",
            "Saving cucumber_13.jpg to cucumber_13.jpg\n",
            "Saving cucumber_13.xml to cucumber_13.xml\n",
            "Saving cucumber_14.jpg to cucumber_14.jpg\n",
            "Saving cucumber_14.xml to cucumber_14.xml\n",
            "Saving cucumber_15.jpg to cucumber_15.jpg\n",
            "Saving cucumber_15.xml to cucumber_15.xml\n",
            "Saving cucumber_16.jpg to cucumber_16.jpg\n",
            "Saving cucumber_16.xml to cucumber_16.xml\n",
            "Saving cucumber_17.jpg to cucumber_17.jpg\n",
            "Saving cucumber_17.xml to cucumber_17.xml\n",
            "Saving cucumber_18.jpg to cucumber_18.jpg\n",
            "Saving cucumber_18.xml to cucumber_18.xml\n",
            "Saving cucumber_19.jpg to cucumber_19.jpg\n",
            "Saving cucumber_19.xml to cucumber_19.xml\n",
            "Saving cucumber_20.jpg to cucumber_20.jpg\n",
            "Saving cucumber_20.xml to cucumber_20.xml\n",
            "Saving cucumber_21.jpg to cucumber_21.jpg\n",
            "Saving cucumber_21.xml to cucumber_21.xml\n",
            "Saving cucumber_22.jpg to cucumber_22.jpg\n",
            "Saving cucumber_22.xml to cucumber_22.xml\n",
            "Saving cucumber_23.jpg to cucumber_23.jpg\n",
            "Saving cucumber_23.xml to cucumber_23.xml\n",
            "Saving cucumber_24.jpg to cucumber_24.jpg\n",
            "Saving cucumber_24.xml to cucumber_24.xml\n",
            "Saving cucumber_25.jpg to cucumber_25.jpg\n",
            "Saving cucumber_25.xml to cucumber_25.xml\n",
            "Saving cucumber_26.jpg to cucumber_26.jpg\n",
            "Saving cucumber_26.xml to cucumber_26.xml\n",
            "Saving cucumber_27.jpg to cucumber_27.jpg\n",
            "Saving cucumber_27.xml to cucumber_27.xml\n",
            "Saving cucumber_28.jpg to cucumber_28.jpg\n",
            "Saving cucumber_28.xml to cucumber_28.xml\n",
            "Saving cucumber_29.jpg to cucumber_29.jpg\n",
            "Saving cucumber_29.xml to cucumber_29.xml\n",
            "Saving cucumber_30.jpg to cucumber_30.jpg\n",
            "Saving cucumber_30.xml to cucumber_30.xml\n",
            "Saving cucumber_31.jpg to cucumber_31.jpg\n",
            "Saving cucumber_31.xml to cucumber_31.xml\n",
            "Saving cucumber_32.jpg to cucumber_32.jpg\n",
            "Saving cucumber_32.xml to cucumber_32.xml\n",
            "Saving cucumber_33.jpg to cucumber_33.jpg\n",
            "Saving cucumber_33.xml to cucumber_33.xml\n",
            "Saving cucumber_34.jpg to cucumber_34.jpg\n",
            "Saving cucumber_34.xml to cucumber_34.xml\n",
            "Saving cucumber_35.jpg to cucumber_35.jpg\n",
            "Saving cucumber_35.xml to cucumber_35.xml\n",
            "Saving cucumber_36.jpg to cucumber_36.jpg\n",
            "Saving cucumber_36.xml to cucumber_36.xml\n",
            "Saving cucumber_37.jpg to cucumber_37.jpg\n",
            "Saving cucumber_37.xml to cucumber_37.xml\n",
            "Saving cucumber_38.jpg to cucumber_38.jpg\n",
            "Saving cucumber_38.xml to cucumber_38.xml\n",
            "Saving cucumber_39.jpg to cucumber_39.jpg\n",
            "Saving cucumber_39.xml to cucumber_39.xml\n",
            "Saving cucumber_40.jpg to cucumber_40.jpg\n",
            "Saving cucumber_40.xml to cucumber_40.xml\n",
            "Saving cucumber_41.jpg to cucumber_41.jpg\n",
            "Saving cucumber_41.xml to cucumber_41.xml\n",
            "Saving cucumber_42.jpg to cucumber_42.jpg\n",
            "Saving cucumber_42.xml to cucumber_42.xml\n",
            "Saving cucumber_43.jpg to cucumber_43.jpg\n",
            "Saving cucumber_43.xml to cucumber_43.xml\n",
            "Saving cucumber_44.jpg to cucumber_44.jpg\n",
            "Saving cucumber_44.xml to cucumber_44.xml\n",
            "Saving cucumber_45.jpg to cucumber_45.jpg\n",
            "Saving cucumber_45.xml to cucumber_45.xml\n",
            "Saving cucumber_46.jpg to cucumber_46.jpg\n",
            "Saving cucumber_46.xml to cucumber_46.xml\n",
            "Saving cucumber_47.jpg to cucumber_47.jpg\n",
            "Saving cucumber_47.xml to cucumber_47.xml\n",
            "Saving cucumber_48.jpg to cucumber_48.jpg\n",
            "Saving cucumber_48.xml to cucumber_48.xml\n",
            "Saving cucumber_49.jpg to cucumber_49.jpg\n",
            "Saving cucumber_49.xml to cucumber_49.xml\n",
            "Saving cucumber_50.jpg to cucumber_50.jpg\n",
            "Saving cucumber_50.xml to cucumber_50.xml\n",
            "Saving cucumber_51.jpg to cucumber_51.jpg\n",
            "Saving cucumber_51.xml to cucumber_51.xml\n",
            "Saving cucumber_52.jpg to cucumber_52.jpg\n",
            "Saving cucumber_52.xml to cucumber_52.xml\n",
            "Saving cucumber_53.jpg to cucumber_53.jpg\n",
            "Saving cucumber_53.xml to cucumber_53.xml\n",
            "Saving cucumber_54.jpg to cucumber_54.jpg\n",
            "Saving cucumber_54.xml to cucumber_54.xml\n",
            "Saving cucumber_55.jpg to cucumber_55.jpg\n",
            "Saving cucumber_55.xml to cucumber_55.xml\n",
            "Saving cucumber_56.jpg to cucumber_56.jpg\n",
            "Saving cucumber_56.xml to cucumber_56.xml\n",
            "Saving cucumber_57.jpg to cucumber_57.jpg\n",
            "Saving cucumber_57.xml to cucumber_57.xml\n",
            "Saving cucumber_58.jpg to cucumber_58.jpg\n",
            "Saving cucumber_58.xml to cucumber_58.xml\n",
            "Saving cucumber_59.jpg to cucumber_59.jpg\n",
            "Saving cucumber_59.xml to cucumber_59.xml\n",
            "Saving cucumber_60.jpg to cucumber_60.jpg\n",
            "Saving cucumber_60.xml to cucumber_60.xml\n",
            "Saving cucumber_61.jpg to cucumber_61.jpg\n",
            "Saving cucumber_61.xml to cucumber_61.xml\n",
            "Saving cucumber_62.jpg to cucumber_62.jpg\n",
            "Saving cucumber_62.xml to cucumber_62.xml\n",
            "Saving cucumber_63.jpg to cucumber_63.jpg\n",
            "Saving cucumber_63.xml to cucumber_63.xml\n",
            "Saving eggplant_1.jpg to eggplant_1.jpg\n",
            "Saving eggplant_1.xml to eggplant_1.xml\n",
            "Saving eggplant_2.jpg to eggplant_2.jpg\n",
            "Saving eggplant_2.xml to eggplant_2.xml\n",
            "Saving eggplant_3.jpg to eggplant_3.jpg\n",
            "Saving eggplant_3.xml to eggplant_3.xml\n",
            "Saving eggplant_4.jpg to eggplant_4.jpg\n",
            "Saving eggplant_4.xml to eggplant_4.xml\n",
            "Saving eggplant_5.jpg to eggplant_5.jpg\n",
            "Saving eggplant_5.xml to eggplant_5.xml\n",
            "Saving eggplant_6.jpg to eggplant_6.jpg\n",
            "Saving eggplant_6.xml to eggplant_6.xml\n",
            "Saving eggplant_7.jpg to eggplant_7.jpg\n",
            "Saving eggplant_7.xml to eggplant_7.xml\n",
            "Saving eggplant_8.jpg to eggplant_8.jpg\n",
            "Saving eggplant_8.xml to eggplant_8.xml\n",
            "Saving eggplant_9.jpg to eggplant_9.jpg\n",
            "Saving eggplant_9.xml to eggplant_9.xml\n",
            "Saving eggplant_10.jpg to eggplant_10.jpg\n",
            "Saving eggplant_10.xml to eggplant_10.xml\n",
            "Saving eggplant_11.jpg to eggplant_11.jpg\n",
            "Saving eggplant_11.xml to eggplant_11.xml\n",
            "Saving eggplant_12.jpg to eggplant_12.jpg\n",
            "Saving eggplant_12.xml to eggplant_12.xml\n",
            "Saving eggplant_13.jpg to eggplant_13.jpg\n",
            "Saving eggplant_13.xml to eggplant_13.xml\n",
            "Saving eggplant_14.jpg to eggplant_14.jpg\n",
            "Saving eggplant_14.xml to eggplant_14.xml\n",
            "Saving eggplant_15.jpg to eggplant_15.jpg\n",
            "Saving eggplant_15.xml to eggplant_15.xml\n",
            "Saving eggplant_16.jpg to eggplant_16.jpg\n",
            "Saving eggplant_16.xml to eggplant_16.xml\n",
            "Saving eggplant_17.jpg to eggplant_17.jpg\n",
            "Saving eggplant_17.xml to eggplant_17.xml\n",
            "Saving eggplant_18.jpg to eggplant_18.jpg\n",
            "Saving eggplant_18.xml to eggplant_18.xml\n",
            "Saving eggplant_19.jpg to eggplant_19.jpg\n",
            "Saving eggplant_19.xml to eggplant_19.xml\n",
            "Saving eggplant_20.jpg to eggplant_20.jpg\n",
            "Saving eggplant_20.xml to eggplant_20.xml\n",
            "Saving eggplant_21.jpg to eggplant_21.jpg\n",
            "Saving eggplant_21.xml to eggplant_21.xml\n",
            "Saving eggplant_22.jpg to eggplant_22.jpg\n",
            "Saving eggplant_22.xml to eggplant_22.xml\n",
            "Saving eggplant_23.jpg to eggplant_23.jpg\n",
            "Saving eggplant_23.xml to eggplant_23.xml\n",
            "Saving eggplant_24.jpg to eggplant_24.jpg\n",
            "Saving eggplant_24.xml to eggplant_24.xml\n",
            "Saving eggplant_25.jpg to eggplant_25.jpg\n",
            "Saving eggplant_25.xml to eggplant_25.xml\n",
            "Saving eggplant_26.jpg to eggplant_26.jpg\n",
            "Saving eggplant_26.xml to eggplant_26.xml\n",
            "Saving eggplant_27.jpg to eggplant_27.jpg\n",
            "Saving eggplant_27.xml to eggplant_27.xml\n",
            "Saving eggplant_28.jpg to eggplant_28.jpg\n",
            "Saving eggplant_28.xml to eggplant_28.xml\n",
            "Saving eggplant_29.jpg to eggplant_29.jpg\n",
            "Saving eggplant_29.xml to eggplant_29.xml\n",
            "Saving eggplant_30.jpg to eggplant_30.jpg\n",
            "Saving eggplant_30.xml to eggplant_30.xml\n",
            "Saving eggplant_31.jpg to eggplant_31.jpg\n",
            "Saving eggplant_31.xml to eggplant_31.xml\n",
            "Saving eggplant_32.jpg to eggplant_32.jpg\n",
            "Saving eggplant_32.xml to eggplant_32.xml\n",
            "Saving eggplant_33.jpg to eggplant_33.jpg\n",
            "Saving eggplant_33.xml to eggplant_33.xml\n",
            "Saving eggplant_34.jpg to eggplant_34.jpg\n",
            "Saving eggplant_34.xml to eggplant_34.xml\n",
            "Saving eggplant_35.jpg to eggplant_35.jpg\n",
            "Saving eggplant_35.xml to eggplant_35.xml\n",
            "Saving eggplant_36.jpg to eggplant_36.jpg\n",
            "Saving eggplant_36.xml to eggplant_36.xml\n",
            "Saving eggplant_37.jpg to eggplant_37.jpg\n",
            "Saving eggplant_37.xml to eggplant_37.xml\n",
            "Saving eggplant_38.jpg to eggplant_38.jpg\n",
            "Saving eggplant_38.xml to eggplant_38.xml\n",
            "Saving eggplant_39.jpg to eggplant_39.jpg\n",
            "Saving eggplant_39.xml to eggplant_39.xml\n",
            "Saving eggplant_40.jpg to eggplant_40.jpg\n",
            "Saving eggplant_40.xml to eggplant_40.xml\n",
            "Saving eggplant_41.jpg to eggplant_41.jpg\n",
            "Saving eggplant_41.xml to eggplant_41.xml\n",
            "Saving eggplant_42.jpg to eggplant_42.jpg\n",
            "Saving eggplant_42.xml to eggplant_42.xml\n",
            "Saving eggplant_43.jpg to eggplant_43.jpg\n",
            "Saving eggplant_43.xml to eggplant_43.xml\n",
            "Saving eggplant_44.jpg to eggplant_44.jpg\n",
            "Saving eggplant_44.xml to eggplant_44.xml\n",
            "Saving eggplant_45.jpg to eggplant_45.jpg\n",
            "Saving eggplant_45.xml to eggplant_45.xml\n",
            "Saving eggplant_46.jpg to eggplant_46.jpg\n",
            "Saving eggplant_46.xml to eggplant_46.xml\n",
            "Saving eggplant_47.jpg to eggplant_47.jpg\n",
            "Saving eggplant_47.xml to eggplant_47.xml\n",
            "Saving eggplant_48.jpg to eggplant_48.jpg\n",
            "Saving eggplant_48.xml to eggplant_48.xml\n",
            "Saving eggplant_49.jpg to eggplant_49.jpg\n",
            "Saving eggplant_49.xml to eggplant_49.xml\n",
            "Saving eggplant_50.jpg to eggplant_50.jpg\n",
            "Saving eggplant_50.xml to eggplant_50.xml\n",
            "Saving eggplant_51.jpg to eggplant_51.jpg\n",
            "Saving eggplant_51.xml to eggplant_51.xml\n",
            "Saving eggplant_52.jpg to eggplant_52.jpg\n",
            "Saving eggplant_52.xml to eggplant_52.xml\n",
            "Saving eggplant_53.jpg to eggplant_53.jpg\n",
            "Saving eggplant_53.xml to eggplant_53.xml\n",
            "Saving eggplant_54.jpg to eggplant_54.jpg\n",
            "Saving eggplant_54.xml to eggplant_54.xml\n",
            "Saving eggplant_55.jpg to eggplant_55.jpg\n",
            "Saving eggplant_55.xml to eggplant_55.xml\n",
            "Saving eggplant_56.jpg to eggplant_56.jpg\n",
            "Saving eggplant_56.xml to eggplant_56.xml\n",
            "Saving eggplant_57.jpg to eggplant_57.jpg\n",
            "Saving eggplant_57.xml to eggplant_57.xml\n",
            "Saving eggplant_58.jpg to eggplant_58.jpg\n",
            "Saving eggplant_58.xml to eggplant_58.xml\n",
            "Saving eggplant_59.jpg to eggplant_59.jpg\n",
            "Saving eggplant_59.xml to eggplant_59.xml\n",
            "Saving eggplant_60.jpg to eggplant_60.jpg\n",
            "Saving eggplant_60.xml to eggplant_60.xml\n",
            "Saving eggplant_61.jpg to eggplant_61.jpg\n",
            "Saving eggplant_61.xml to eggplant_61.xml\n",
            "Saving eggplant_62.jpg to eggplant_62.jpg\n",
            "Saving eggplant_62.xml to eggplant_62.xml\n",
            "Saving mushroom_1.jpg to mushroom_1.jpg\n",
            "Saving mushroom_1.xml to mushroom_1.xml\n",
            "Saving mushroom_2.jpg to mushroom_2.jpg\n",
            "Saving mushroom_2.xml to mushroom_2.xml\n",
            "Saving mushroom_3.jpg to mushroom_3.jpg\n",
            "Saving mushroom_3.xml to mushroom_3.xml\n",
            "Saving mushroom_4.jpg to mushroom_4.jpg\n",
            "Saving mushroom_4.xml to mushroom_4.xml\n",
            "Saving mushroom_5.jpg to mushroom_5.jpg\n",
            "Saving mushroom_5.xml to mushroom_5.xml\n",
            "Saving mushroom_6.jpg to mushroom_6.jpg\n",
            "Saving mushroom_6.xml to mushroom_6.xml\n",
            "Saving mushroom_7.jpg to mushroom_7.jpg\n",
            "Saving mushroom_7.xml to mushroom_7.xml\n",
            "Saving mushroom_8.jpg to mushroom_8.jpg\n",
            "Saving mushroom_8.xml to mushroom_8.xml\n",
            "Saving mushroom_9.jpg to mushroom_9.jpg\n",
            "Saving mushroom_9.xml to mushroom_9.xml\n",
            "Saving mushroom_10.jpg to mushroom_10.jpg\n",
            "Saving mushroom_10.xml to mushroom_10.xml\n",
            "Saving mushroom_11.jpg to mushroom_11.jpg\n",
            "Saving mushroom_11.xml to mushroom_11.xml\n",
            "Saving mushroom_12.jpg to mushroom_12.jpg\n",
            "Saving mushroom_12.xml to mushroom_12.xml\n",
            "Saving mushroom_13.jpg to mushroom_13.jpg\n",
            "Saving mushroom_13.xml to mushroom_13.xml\n",
            "Saving mushroom_14.jpg to mushroom_14.jpg\n",
            "Saving mushroom_14.xml to mushroom_14.xml\n",
            "Saving mushroom_15.jpg to mushroom_15.jpg\n",
            "Saving mushroom_15.xml to mushroom_15.xml\n",
            "Saving mushroom_16.jpg to mushroom_16.jpg\n",
            "Saving mushroom_16.xml to mushroom_16.xml\n",
            "Saving mushroom_17.jpg to mushroom_17.jpg\n",
            "Saving mushroom_17.xml to mushroom_17.xml\n",
            "Saving mushroom_18.jpg to mushroom_18.jpg\n",
            "Saving mushroom_18.xml to mushroom_18.xml\n",
            "Saving mushroom_19.jpg to mushroom_19.jpg\n",
            "Saving mushroom_19.xml to mushroom_19.xml\n",
            "Saving mushroom_20.jpg to mushroom_20.jpg\n",
            "Saving mushroom_20.xml to mushroom_20.xml\n",
            "Saving mushroom_21.jpg to mushroom_21.jpg\n",
            "Saving mushroom_21.xml to mushroom_21.xml\n",
            "Saving mushroom_22.jpg to mushroom_22.jpg\n",
            "Saving mushroom_22.xml to mushroom_22.xml\n",
            "Saving mushroom_23.jpg to mushroom_23.jpg\n",
            "Saving mushroom_23.xml to mushroom_23.xml\n",
            "Saving mushroom_24.jpg to mushroom_24.jpg\n",
            "Saving mushroom_24.xml to mushroom_24.xml\n",
            "Saving mushroom_25.jpg to mushroom_25.jpg\n",
            "Saving mushroom_25.xml to mushroom_25.xml\n",
            "Saving mushroom_26.jpg to mushroom_26.jpg\n",
            "Saving mushroom_26.xml to mushroom_26.xml\n",
            "Saving mushroom_27.jpg to mushroom_27.jpg\n",
            "Saving mushroom_27.xml to mushroom_27.xml\n",
            "Saving mushroom_28.jpg to mushroom_28.jpg\n",
            "Saving mushroom_28.xml to mushroom_28.xml\n",
            "Saving mushroom_29.jpg to mushroom_29.jpg\n",
            "Saving mushroom_29.xml to mushroom_29.xml\n",
            "Saving mushroom_30.jpg to mushroom_30.jpg\n",
            "Saving mushroom_30.xml to mushroom_30.xml\n",
            "Saving mushroom_31.jpg to mushroom_31.jpg\n",
            "Saving mushroom_31.xml to mushroom_31.xml\n",
            "Saving mushroom_32.jpg to mushroom_32.jpg\n",
            "Saving mushroom_32.xml to mushroom_32.xml\n",
            "Saving mushroom_33.jpg to mushroom_33.jpg\n",
            "Saving mushroom_33.xml to mushroom_33.xml\n",
            "Saving mushroom_34.jpg to mushroom_34.jpg\n",
            "Saving mushroom_34.xml to mushroom_34.xml\n",
            "Saving mushroom_35.jpg to mushroom_35.jpg\n",
            "Saving mushroom_35.xml to mushroom_35.xml\n",
            "Saving mushroom_36.jpg to mushroom_36.jpg\n",
            "Saving mushroom_36.xml to mushroom_36.xml\n",
            "Saving mushroom_37.jpg to mushroom_37.jpg\n",
            "Saving mushroom_37.xml to mushroom_37.xml\n",
            "Saving mushroom_38.jpg to mushroom_38.jpg\n",
            "Saving mushroom_38.xml to mushroom_38.xml\n",
            "Saving mushroom_39.jpg to mushroom_39.jpg\n",
            "Saving mushroom_39.xml to mushroom_39.xml\n",
            "Saving mushroom_40.jpg to mushroom_40.jpg\n",
            "Saving mushroom_40.xml to mushroom_40.xml\n",
            "Saving mushroom_41.jpg to mushroom_41.jpg\n",
            "Saving mushroom_41.xml to mushroom_41.xml\n",
            "Saving mushroom_42.jpg to mushroom_42.jpg\n",
            "Saving mushroom_42.xml to mushroom_42.xml\n",
            "Saving mushroom_43.jpg to mushroom_43.jpg\n",
            "Saving mushroom_43.xml to mushroom_43.xml\n",
            "Saving mushroom_44.jpg to mushroom_44.jpg\n",
            "Saving mushroom_44.xml to mushroom_44.xml\n",
            "Saving mushroom_45.jpg to mushroom_45.jpg\n",
            "Saving mushroom_45.xml to mushroom_45.xml\n",
            "Saving mushroom_46.jpg to mushroom_46.jpg\n",
            "Saving mushroom_46.xml to mushroom_46.xml\n",
            "Saving mushroom_47.jpg to mushroom_47.jpg\n",
            "Saving mushroom_47.xml to mushroom_47.xml\n",
            "Saving mushroom_48.jpg to mushroom_48.jpg\n",
            "Saving mushroom_48.xml to mushroom_48.xml\n",
            "Saving mushroom_49.jpg to mushroom_49.jpg\n",
            "Saving mushroom_49.xml to mushroom_49.xml\n",
            "Saving mushroom_50.jpg to mushroom_50.jpg\n",
            "Saving mushroom_50.xml to mushroom_50.xml\n",
            "Saving mushroom_51.jpg to mushroom_51.jpg\n",
            "Saving mushroom_51.xml to mushroom_51.xml\n",
            "Saving mushroom_52.jpg to mushroom_52.jpg\n",
            "Saving mushroom_52.xml to mushroom_52.xml\n",
            "Saving mushroom_53.jpg to mushroom_53.jpg\n",
            "Saving mushroom_53.xml to mushroom_53.xml\n",
            "Saving mushroom_54.jpg to mushroom_54.jpg\n",
            "Saving mushroom_54.xml to mushroom_54.xml\n",
            "Saving mushroom_55.jpg to mushroom_55.jpg\n",
            "Saving mushroom_55.xml to mushroom_55.xml\n",
            "Saving mushroom_56.jpg to mushroom_56.jpg\n",
            "Saving mushroom_56.xml to mushroom_56.xml\n",
            "Saving mushroom_57.jpg to mushroom_57.jpg\n",
            "Saving mushroom_57.xml to mushroom_57.xml\n",
            "Saving mushroom_58.jpg to mushroom_58.jpg\n",
            "Saving mushroom_58.xml to mushroom_58.xml\n",
            "Saving mushroom_59.jpg to mushroom_59.jpg\n",
            "Saving mushroom_59.xml to mushroom_59.xml\n",
            "Saving mushroom_60.jpg to mushroom_60.jpg\n",
            "Saving mushroom_60.xml to mushroom_60.xml\n",
            "Saving mushroom_61.jpg to mushroom_61.jpg\n",
            "Saving mushroom_61.xml to mushroom_61.xml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41rxCQJzUEc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing, svm\n",
        "from math import *\n",
        "from time import sleep\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2RfHpMyaqE9",
        "colab_type": "code",
        "outputId": "4d427063-ff3b-4421-c3d0-37ff60364c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "def xmlread(file):   \n",
        "    keys = ['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'xmid', 'ymid', 'h', 'w']\n",
        "    file = file.decode()\n",
        "    file = file.split('\\n')\n",
        "    useful = [file[2]]+file[19 : 23]\n",
        "\n",
        "\n",
        "    for i in range(len(useful)):\n",
        "        useful[i] = useful[i].replace(\"\\t\",\"\")\n",
        "        useful[i] = useful[i].replace(\"/\",\"\")\n",
        "        useful[i] = useful[i].replace(\"<\"+keys[0]+\">\",\"\")\n",
        "        useful[i] = useful[i].replace(\"<\"+keys[1]+\">\",\"\")\n",
        "        useful[i] = useful[i].replace(\"<\"+keys[2]+\">\",\"\")\n",
        "        useful[i] = useful[i].replace(\"<\"+keys[3]+\">\",\"\")\n",
        "        useful[i] = useful[i].replace(\"<\"+keys[4]+\">\",\"\")\n",
        "        \n",
        "        \n",
        "    xmid = (int(useful[1]) + int(useful[3]))/2.\n",
        "    ymid = (int(useful[2]) + int(useful[4]))/2.\n",
        "    \n",
        "    h = int(useful[4]) - int(useful[2])\n",
        "    w = int(useful[3]) - int(useful[1])\n",
        "\n",
        "    val = {keys[0]:useful[0],\n",
        "          keys[5]:int(xmid),\n",
        "          keys[6]:int(ymid),\n",
        "          keys[7]:h,\n",
        "          keys[8]:w}\n",
        "\n",
        "    bpnt = [int(xmid)/227, int(ymid)/227, h/227, w/227]\n",
        "    return bpnt\n",
        "\n",
        "\n",
        "def getdata(uploads):\n",
        "    dset = []\n",
        "    files = list(uploads.keys())\n",
        "    #print(files)\n",
        "    for i in range(0,len(files), 2):\n",
        "        j = i + 1\n",
        "        #print(files[i], files[j])\n",
        "        img = cv2.imread(files[i])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        #plt.imshow(img)\n",
        "        location = xmlread(uploads[files[j]])\n",
        "        if 'cucumber' in files[i]:\n",
        "            #classif = np.array([1, 0, 0])\n",
        "            classif = 0\n",
        "            #classif = np.array([[1], [0], [0]])\n",
        "        elif 'mushroom' in files[i]:\n",
        "            #classif = np.array([0, 0, 1])\n",
        "            classif = 2\n",
        "            #classif = np.array([[0], [0], [1]])\n",
        "        elif 'eggplant' in files[i]:\n",
        "            #classif = np.array([0, 1, 0])\n",
        "            classif = 1\n",
        "            #classif = np.array([[0], [1], [0]])\n",
        "        else:\n",
        "            #classif = [0, 0, 0]\n",
        "            classif = 0\n",
        "        vec = [np.array(img)/255, classif, location]\n",
        "        dset.append(vec)\n",
        "    return dset\n",
        "\n",
        "data = getdata(uploads)\n",
        "#print(data[1])\n",
        "\n",
        "shuffle(data)\n",
        "shuffle(data)\n",
        "\n",
        "#print(data)\n",
        "\n",
        "trainlen = int(len(data)*0.9)\n",
        "datan = np.array(data)\n",
        "print(datan.shape)\n",
        "\n",
        "train = datan[:trainlen]\n",
        "test = datan[trainlen:]\n",
        "\n",
        "xtrain = train[:, 0]\n",
        "xtest = test[:, 0]\n",
        "\n",
        "xtrain = np.array(xtrain.tolist())\n",
        "xtest = np.array(xtest.tolist())\n",
        "\n",
        "classtr = train[:, 1]\n",
        "classte = test[:, 1]\n",
        "\n",
        "classtr = np.array(classtr.tolist())\n",
        "classtr = classtr.flatten()\n",
        "classte = np.array(classte.tolist())\n",
        "classte = classte.flatten()\n",
        "\n",
        "\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "print(classtr, classte)\n",
        "\n",
        "boxtr = train[:, 2]\n",
        "boxte = test[:, 2]\n",
        "\n",
        "boxtr = np.array(boxtr.tolist())\n",
        "boxte = np.array(boxte.tolist())\n",
        "xtrain = xtrain[:, :, :, np.newaxis]\n",
        "xtest = xtest[:, :, :, np.newaxis]\n",
        "\n",
        "print(xtrain.shape)\n",
        "print(xtest.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(186, 3)\n",
            "[0 0 1 1 2 2 1 1 1 1 1 0 2 2 0 0 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 1 1 1 1 2 2\n",
            " 2 0 1 2 0 2 2 1 2 2 1 0 2 0 2 1 0 2 1 0 1 2 0 2 1 2 0 1 0 0 2 0 2 2 2 2 2\n",
            " 0 1 2 0 0 0 0 0 0 0 0 1 1 0 1 0 2 1 2 0 0 0 2 1 1 1 1 0 2 2 1 0 0 2 0 0 2\n",
            " 1 0 0 0 2 0 0 1 0 1 2 1 0 0 1 2 2 2 2 0 2 0 0 2 2 0 1 2 1 1 2 1 1 1 0 2 2\n",
            " 2 1 0 0 0 2 2 0 1 1 1 2 2 1 0 1 2 1 0] [2 0 2 1 0 0 0 1 1 1 1 0 0 0 0 0 2 1 1]\n",
            "(167, 227, 227, 1)\n",
            "(19, 227, 227, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvcavyGQev3b",
        "colab_type": "code",
        "outputId": "8e9fcbe2-7908-4f95-a5ad-c7d3d71e44ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as ks\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "class LocalNet(Model):\n",
        "    @staticmethod\n",
        "    def main_net(inputs):\n",
        "        x = Conv2D(filters = 96, kernel_size = (11,11), strides = (4,4), padding = \"same\", activation = 'relu')(inputs)\n",
        "        x = MaxPool2D(pool_size = (3,3), strides = (2,2), padding = \"same\")(x)\n",
        "        #x = BatchNormalization()(x)\n",
        "        \n",
        "        x = Conv2D(filters = 256, kernel_size = (5,5), strides = (1,1), padding = \"same\", activation = 'relu')(x)\n",
        "        x = MaxPool2D(pool_size = (3,3), strides = (2,2), padding = \"same\")(x)\n",
        "        #x = BatchNormalization()(x)\n",
        "        \n",
        "        x = Conv2D(filters = 384, kernel_size = (3,3), strides = (1,1), padding = \"same\", activation = 'relu')(x)\n",
        "        x = Conv2D(filters = 384, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu')(x)\n",
        "        x = Conv2D(filters = 256, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu')(x)\n",
        "        x = MaxPool2D(pool_size = (3,3), strides = (2,2), padding = 'same')(x)\n",
        "        #x = BatchNormalization()(x)\n",
        "        \n",
        "        #x = Flatten()(x)\n",
        "        \n",
        "#         x = Dense(units = 4096,activation = 'relu')(x)\n",
        "#         x = Dropout(0.4)(x)\n",
        "        \n",
        "#         x = Dense(units = 4096,activation = 'relu')(x)\n",
        "#         x = Dropout(0.4)(x)\n",
        "        \n",
        "#         x = Dense(units = 1000,activation = 'relu')(x)\n",
        "#         x = Dropout(0.4)(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    @staticmethod\n",
        "    def build_class(x):\n",
        "        #sh = tf.shape(x)[:2]\n",
        "        x = Conv2D(filters = 4096, kernel_size = (8, 8), activation = 'relu')(x)\n",
        " \n",
        "        x = Dropout(0.3)(x)\n",
        "        #sh = tf.shape(x)[:2]\n",
        "        x = Conv2D(filters = 4096, kernel_size = (1, 1), activation = 'relu')(x)\n",
        "\n",
        "        x = Dropout(0.3)(x)\n",
        "        #sh = tf.shape(x)[:2]\n",
        "        x = Conv2D(filters = 1000, kernel_size = (1, 1), activation = 'relu')(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        \n",
        "        #shape = tf.shape(x)[:2]\n",
        "        x = Conv2D(filters = 3, kernel_size = (1, 1), activation = 'softmax', name = 'classif')(x)\n",
        "        return x\n",
        "    \n",
        "    @staticmethod\n",
        "    def build_box(x):   \n",
        "        x = Flatten()(x)\n",
        "        \n",
        "        x = Dense(units = 1024,activation = 'relu')(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "        \n",
        "        x = Dense(units = 512,activation = 'relu')(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "        \n",
        "        x = Dense(units = 256,activation = 'relu')(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "        \n",
        "        x = Dense(units = 4, name = 'box')(x)\n",
        "        return x\n",
        "    \n",
        "    @staticmethod\n",
        "    def build(h, w):\n",
        "        \n",
        "        inputShape = (h, w, 1)\n",
        "        \n",
        "        inputimg = Input(shape = inputShape)\n",
        "        midval = LocalNet.main_net(inputimg)\n",
        "        classif = LocalNet.build_class(midval)\n",
        "        box = LocalNet.build_box(midval)\n",
        "        \n",
        "        model = Model(inputs = inputimg, \n",
        "                     outputs = [classif, box],\n",
        "                     name = 'LocalNet')\n",
        "        \n",
        "        return model\n",
        "        \n",
        "model = LocalNet.build(227, 227)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"LocalNet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 227, 227, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 57, 57, 96)   11712       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 29, 29, 96)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 29, 29, 256)  614656      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 15, 15, 256)  0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 15, 15, 384)  885120      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 15, 15, 384)  1327488     conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 15, 15, 256)  884992      conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 256)    0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 16384)        0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 1, 1, 4096)   67112960    max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         16778240    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1, 1, 4096)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 1, 1, 4096)   16781312    dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          524800      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1, 1, 4096)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 1, 1, 1000)   4097000     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          131328      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1, 1, 1000)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "classif (Conv2D)                (None, 1, 1, 3)      3003        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "box (Dense)                     (None, 4)            1028        dropout_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,153,639\n",
            "Trainable params: 109,153,639\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZrVxGE9_L1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hyperparameters \n",
        "EPOCHS = 50\n",
        "lr = 0.000006\n",
        "step_size = 8\n",
        "op_classes = 3\n",
        "op_boxvals = 4\n",
        "fc_nodes1 = 4096\n",
        "fc_nodes2 = 4096\n",
        "batchSize = 20\n",
        "img_size = 227\n",
        "\n",
        "classif = 'classif'\n",
        "boxif = 'box'\n",
        "\n",
        "losses = {'classif': ks.losses.SparseCategoricalCrossentropy(),\n",
        "          'box': ks.losses.MeanSquaredError()}\n",
        "\n",
        "lossWeights = {'classif': 10.0, 'box': 1.0}\n",
        "\n",
        "#listmets = None\n",
        "listmets = {'classif': ks.losses.SparseCategoricalCrossentropy(), 'box': ks.losses.MeanSquaredError()}\n",
        "opt = ks.optimizers.Adam(learning_rate = lr)\n",
        "\n",
        "model.compile(optimizer = opt, loss = losses, loss_weights = lossWeights, metrics = ['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4a721169-c60e-492d-c862-10b9dc6bd8a0",
        "id": "Dmig6kiAuVwa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "validationdata = (xtest, {'classif': classte, 'box':boxte})\n",
        "model.fit(x = xtrain, y = {'classif': classtr, 'box': boxtr}, validation_data = validationdata , batch_size = step_size, epochs = EPOCHS, verbose = 1)\n",
        "\n",
        "#fix losses"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0716 01:55:18.040661 139953127716736 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 167 samples, validate on 19 samples\n",
            "Epoch 1/50\n",
            "167/167 [==============================] - 8s 51ms/sample - loss: 11.2922 - classif_loss: 1.0997 - box_loss: 0.2951 - classif_accuracy: 0.2619 - box_accuracy: 0.3353 - val_loss: 11.1289 - val_classif_loss: 1.0911 - val_box_loss: 0.2177 - val_classif_accuracy: 0.4526 - val_box_accuracy: 0.1579\n",
            "Epoch 2/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 11.1329 - classif_loss: 1.0961 - box_loss: 0.1730 - classif_accuracy: 0.3108 - box_accuracy: 0.3832 - val_loss: 10.9923 - val_classif_loss: 1.0880 - val_box_loss: 0.0785 - val_classif_accuracy: 0.3358 - val_box_accuracy: 0.1579\n",
            "Epoch 3/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 11.0621 - classif_loss: 1.0978 - box_loss: 0.0826 - classif_accuracy: 0.3228 - box_accuracy: 0.4072 - val_loss: 10.8678 - val_classif_loss: 1.0840 - val_box_loss: 0.0320 - val_classif_accuracy: 0.3723 - val_box_accuracy: 0.1579\n",
            "Epoch 4/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 11.0687 - classif_loss: 1.1002 - box_loss: 0.0666 - classif_accuracy: 0.2987 - box_accuracy: 0.4311 - val_loss: 10.8833 - val_classif_loss: 1.0881 - val_box_loss: 0.0367 - val_classif_accuracy: 0.5255 - val_box_accuracy: 0.1579\n",
            "Epoch 5/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 10.9904 - classif_loss: 1.0921 - box_loss: 0.0697 - classif_accuracy: 0.3236 - box_accuracy: 0.4072 - val_loss: 10.8673 - val_classif_loss: 1.0831 - val_box_loss: 0.0247 - val_classif_accuracy: 0.3358 - val_box_accuracy: 0.1579\n",
            "Epoch 6/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 10.8660 - classif_loss: 1.0806 - box_loss: 0.0607 - classif_accuracy: 0.3521 - box_accuracy: 0.4132 - val_loss: 10.8231 - val_classif_loss: 1.0779 - val_box_loss: 0.0269 - val_classif_accuracy: 0.3869 - val_box_accuracy: 0.2105\n",
            "Epoch 7/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 10.8363 - classif_loss: 1.0774 - box_loss: 0.0616 - classif_accuracy: 0.3461 - box_accuracy: 0.4251 - val_loss: 10.5807 - val_classif_loss: 1.0612 - val_box_loss: 0.0255 - val_classif_accuracy: 0.4088 - val_box_accuracy: 0.1579\n",
            "Epoch 8/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 10.8072 - classif_loss: 1.0749 - box_loss: 0.0579 - classif_accuracy: 0.3258 - box_accuracy: 0.4311 - val_loss: 10.5218 - val_classif_loss: 1.0481 - val_box_loss: 0.0284 - val_classif_accuracy: 0.3723 - val_box_accuracy: 0.1579\n",
            "Epoch 9/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 10.4310 - classif_loss: 1.0363 - box_loss: 0.0669 - classif_accuracy: 0.3815 - box_accuracy: 0.3174 - val_loss: 10.2481 - val_classif_loss: 1.0234 - val_box_loss: 0.0314 - val_classif_accuracy: 0.3139 - val_box_accuracy: 0.1579\n",
            "Epoch 10/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 9.7942 - classif_loss: 0.9725 - box_loss: 0.0655 - classif_accuracy: 0.3649 - box_accuracy: 0.4251 - val_loss: 9.8447 - val_classif_loss: 0.9852 - val_box_loss: 0.0235 - val_classif_accuracy: 0.2920 - val_box_accuracy: 0.2105\n",
            "Epoch 11/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 9.0053 - classif_loss: 0.8935 - box_loss: 0.0662 - classif_accuracy: 0.3679 - box_accuracy: 0.3653 - val_loss: 8.8290 - val_classif_loss: 0.8306 - val_box_loss: 0.0309 - val_classif_accuracy: 0.3431 - val_box_accuracy: 0.1579\n",
            "Epoch 12/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 7.8180 - classif_loss: 0.7753 - box_loss: 0.0683 - classif_accuracy: 0.3649 - box_accuracy: 0.4132 - val_loss: 7.6565 - val_classif_loss: 0.7606 - val_box_loss: 0.0264 - val_classif_accuracy: 0.4015 - val_box_accuracy: 0.2105\n",
            "Epoch 13/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 7.0922 - classif_loss: 0.7025 - box_loss: 0.0589 - classif_accuracy: 0.3973 - box_accuracy: 0.4431 - val_loss: 11.2596 - val_classif_loss: 1.0134 - val_box_loss: 0.0211 - val_classif_accuracy: 0.2920 - val_box_accuracy: 0.2632\n",
            "Epoch 14/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 6.5733 - classif_loss: 0.6517 - box_loss: 0.0628 - classif_accuracy: 0.3672 - box_accuracy: 0.3832 - val_loss: 7.4716 - val_classif_loss: 0.7436 - val_box_loss: 0.0215 - val_classif_accuracy: 0.3577 - val_box_accuracy: 0.5263\n",
            "Epoch 15/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 5.9999 - classif_loss: 0.5944 - box_loss: 0.0521 - classif_accuracy: 0.3777 - box_accuracy: 0.5030 - val_loss: 7.4389 - val_classif_loss: 0.6604 - val_box_loss: 0.0217 - val_classif_accuracy: 0.3869 - val_box_accuracy: 0.3684\n",
            "Epoch 16/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 5.7049 - classif_loss: 0.5652 - box_loss: 0.0628 - classif_accuracy: 0.3770 - box_accuracy: 0.4311 - val_loss: 10.1622 - val_classif_loss: 0.8384 - val_box_loss: 0.0261 - val_classif_accuracy: 0.3650 - val_box_accuracy: 0.6842\n",
            "Epoch 17/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 5.8569 - classif_loss: 0.5799 - box_loss: 0.0593 - classif_accuracy: 0.3898 - box_accuracy: 0.4790 - val_loss: 8.1348 - val_classif_loss: 0.7029 - val_box_loss: 0.0218 - val_classif_accuracy: 0.3869 - val_box_accuracy: 0.2105\n",
            "Epoch 18/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 5.1258 - classif_loss: 0.5078 - box_loss: 0.0534 - classif_accuracy: 0.3717 - box_accuracy: 0.4671 - val_loss: 8.9806 - val_classif_loss: 1.2787 - val_box_loss: 0.0266 - val_classif_accuracy: 0.3431 - val_box_accuracy: 0.4211\n",
            "Epoch 19/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 4.5615 - classif_loss: 0.4518 - box_loss: 0.0487 - classif_accuracy: 0.4041 - box_accuracy: 0.4790 - val_loss: 7.7537 - val_classif_loss: 0.8437 - val_box_loss: 0.0181 - val_classif_accuracy: 0.4234 - val_box_accuracy: 0.5789\n",
            "Epoch 20/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 4.7875 - classif_loss: 0.4713 - box_loss: 0.0532 - classif_accuracy: 0.4041 - box_accuracy: 0.4790 - val_loss: 7.9392 - val_classif_loss: 0.6350 - val_box_loss: 0.0208 - val_classif_accuracy: 0.3796 - val_box_accuracy: 0.4737\n",
            "Epoch 21/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 4.3293 - classif_loss: 0.4269 - box_loss: 0.0522 - classif_accuracy: 0.3860 - box_accuracy: 0.5210 - val_loss: 8.9441 - val_classif_loss: 0.7359 - val_box_loss: 0.0205 - val_classif_accuracy: 0.3504 - val_box_accuracy: 0.5789\n",
            "Epoch 22/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 3.9843 - classif_loss: 0.3956 - box_loss: 0.0536 - classif_accuracy: 0.4003 - box_accuracy: 0.4611 - val_loss: 9.0187 - val_classif_loss: 0.9870 - val_box_loss: 0.0186 - val_classif_accuracy: 0.3504 - val_box_accuracy: 0.5789\n",
            "Epoch 23/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 4.2702 - classif_loss: 0.4228 - box_loss: 0.0529 - classif_accuracy: 0.3875 - box_accuracy: 0.4790 - val_loss: 9.1354 - val_classif_loss: 1.2627 - val_box_loss: 0.0249 - val_classif_accuracy: 0.3869 - val_box_accuracy: 0.5263\n",
            "Epoch 24/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 3.9403 - classif_loss: 0.3887 - box_loss: 0.0466 - classif_accuracy: 0.3853 - box_accuracy: 0.4910 - val_loss: 8.5267 - val_classif_loss: 0.7471 - val_box_loss: 0.0181 - val_classif_accuracy: 0.4307 - val_box_accuracy: 0.5789\n",
            "Epoch 25/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 3.4687 - classif_loss: 0.3437 - box_loss: 0.0422 - classif_accuracy: 0.4078 - box_accuracy: 0.5449 - val_loss: 9.7678 - val_classif_loss: 0.7999 - val_box_loss: 0.0200 - val_classif_accuracy: 0.4088 - val_box_accuracy: 0.6316\n",
            "Epoch 26/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 3.6434 - classif_loss: 0.3587 - box_loss: 0.0470 - classif_accuracy: 0.4409 - box_accuracy: 0.5030 - val_loss: 8.5309 - val_classif_loss: 0.6986 - val_box_loss: 0.0245 - val_classif_accuracy: 0.5182 - val_box_accuracy: 0.5789\n",
            "Epoch 27/50\n",
            "167/167 [==============================] - 3s 18ms/sample - loss: 3.8349 - classif_loss: 0.3785 - box_loss: 0.0470 - classif_accuracy: 0.4221 - box_accuracy: 0.4970 - val_loss: 10.2075 - val_classif_loss: 1.3804 - val_box_loss: 0.0236 - val_classif_accuracy: 0.4088 - val_box_accuracy: 0.5789\n",
            "Epoch 28/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 3.5803 - classif_loss: 0.3557 - box_loss: 0.0473 - classif_accuracy: 0.3822 - box_accuracy: 0.5509 - val_loss: 9.2221 - val_classif_loss: 0.8319 - val_box_loss: 0.0186 - val_classif_accuracy: 0.4672 - val_box_accuracy: 0.6316\n",
            "Epoch 29/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 3.3895 - classif_loss: 0.3353 - box_loss: 0.0465 - classif_accuracy: 0.3853 - box_accuracy: 0.5389 - val_loss: 10.4364 - val_classif_loss: 0.8462 - val_box_loss: 0.0201 - val_classif_accuracy: 0.3504 - val_box_accuracy: 0.5789\n",
            "Epoch 30/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 3.3313 - classif_loss: 0.3282 - box_loss: 0.0446 - classif_accuracy: 0.4003 - box_accuracy: 0.5090 - val_loss: 8.9432 - val_classif_loss: 0.7244 - val_box_loss: 0.0153 - val_classif_accuracy: 0.3504 - val_box_accuracy: 0.5789\n",
            "Epoch 31/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 3.0969 - classif_loss: 0.3054 - box_loss: 0.0447 - classif_accuracy: 0.4138 - box_accuracy: 0.5030 - val_loss: 9.5557 - val_classif_loss: 1.1126 - val_box_loss: 0.0176 - val_classif_accuracy: 0.3577 - val_box_accuracy: 0.6316\n",
            "Epoch 32/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 3.4969 - classif_loss: 0.3440 - box_loss: 0.0419 - classif_accuracy: 0.3883 - box_accuracy: 0.5090 - val_loss: 9.1887 - val_classif_loss: 0.7561 - val_box_loss: 0.0196 - val_classif_accuracy: 0.3577 - val_box_accuracy: 0.5789\n",
            "Epoch 33/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.8656 - classif_loss: 0.2835 - box_loss: 0.0448 - classif_accuracy: 0.3995 - box_accuracy: 0.4970 - val_loss: 10.3367 - val_classif_loss: 0.8261 - val_box_loss: 0.0223 - val_classif_accuracy: 0.4161 - val_box_accuracy: 0.5789\n",
            "Epoch 34/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 3.1794 - classif_loss: 0.3127 - box_loss: 0.0455 - classif_accuracy: 0.4071 - box_accuracy: 0.5509 - val_loss: 10.2123 - val_classif_loss: 0.9521 - val_box_loss: 0.0177 - val_classif_accuracy: 0.3869 - val_box_accuracy: 0.6316\n",
            "Epoch 35/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.7763 - classif_loss: 0.2749 - box_loss: 0.0498 - classif_accuracy: 0.4018 - box_accuracy: 0.5030 - val_loss: 10.1091 - val_classif_loss: 1.2670 - val_box_loss: 0.0225 - val_classif_accuracy: 0.4161 - val_box_accuracy: 0.6316\n",
            "Epoch 36/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.8485 - classif_loss: 0.2792 - box_loss: 0.0428 - classif_accuracy: 0.4041 - box_accuracy: 0.5808 - val_loss: 9.3523 - val_classif_loss: 0.8484 - val_box_loss: 0.0155 - val_classif_accuracy: 0.4307 - val_box_accuracy: 0.5789\n",
            "Epoch 37/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.5506 - classif_loss: 0.2495 - box_loss: 0.0441 - classif_accuracy: 0.4146 - box_accuracy: 0.5988 - val_loss: 11.2668 - val_classif_loss: 0.8985 - val_box_loss: 0.0181 - val_classif_accuracy: 0.4088 - val_box_accuracy: 0.6316\n",
            "Epoch 38/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.4149 - classif_loss: 0.2360 - box_loss: 0.0450 - classif_accuracy: 0.4093 - box_accuracy: 0.5749 - val_loss: 10.1667 - val_classif_loss: 0.8283 - val_box_loss: 0.0155 - val_classif_accuracy: 0.4234 - val_box_accuracy: 0.5789\n",
            "Epoch 39/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.2856 - classif_loss: 0.2245 - box_loss: 0.0406 - classif_accuracy: 0.3995 - box_accuracy: 0.5569 - val_loss: 10.6563 - val_classif_loss: 0.9643 - val_box_loss: 0.0179 - val_classif_accuracy: 0.3942 - val_box_accuracy: 0.5789\n",
            "Epoch 40/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.6792 - classif_loss: 0.2630 - box_loss: 0.0421 - classif_accuracy: 0.3920 - box_accuracy: 0.5210 - val_loss: 10.4428 - val_classif_loss: 1.8801 - val_box_loss: 0.0167 - val_classif_accuracy: 0.4161 - val_box_accuracy: 0.6316\n",
            "Epoch 41/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.2866 - classif_loss: 0.2238 - box_loss: 0.0399 - classif_accuracy: 0.4131 - box_accuracy: 0.6168 - val_loss: 11.0928 - val_classif_loss: 0.8808 - val_box_loss: 0.0156 - val_classif_accuracy: 0.3723 - val_box_accuracy: 0.6316\n",
            "Epoch 42/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.4729 - classif_loss: 0.2418 - box_loss: 0.0445 - classif_accuracy: 0.4026 - box_accuracy: 0.5269 - val_loss: 9.9051 - val_classif_loss: 0.7885 - val_box_loss: 0.0146 - val_classif_accuracy: 0.4526 - val_box_accuracy: 0.6316\n",
            "Epoch 43/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.0224 - classif_loss: 0.1980 - box_loss: 0.0387 - classif_accuracy: 0.4409 - box_accuracy: 0.5569 - val_loss: 11.3280 - val_classif_loss: 1.4381 - val_box_loss: 0.0204 - val_classif_accuracy: 0.3942 - val_box_accuracy: 0.5789\n",
            "Epoch 44/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.1370 - classif_loss: 0.2093 - box_loss: 0.0399 - classif_accuracy: 0.4236 - box_accuracy: 0.5689 - val_loss: 10.4401 - val_classif_loss: 0.8615 - val_box_loss: 0.0177 - val_classif_accuracy: 0.3869 - val_box_accuracy: 0.5789\n",
            "Epoch 45/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.4126 - classif_loss: 0.2360 - box_loss: 0.0406 - classif_accuracy: 0.3965 - box_accuracy: 0.6108 - val_loss: 9.8195 - val_classif_loss: 0.8097 - val_box_loss: 0.0209 - val_classif_accuracy: 0.4745 - val_box_accuracy: 0.5789\n",
            "Epoch 46/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.3214 - classif_loss: 0.2271 - box_loss: 0.0420 - classif_accuracy: 0.3905 - box_accuracy: 0.5329 - val_loss: 11.9422 - val_classif_loss: 1.5997 - val_box_loss: 0.0159 - val_classif_accuracy: 0.4015 - val_box_accuracy: 0.5789\n",
            "Epoch 47/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.6674 - classif_loss: 0.2626 - box_loss: 0.0396 - classif_accuracy: 0.3868 - box_accuracy: 0.5808 - val_loss: 10.0283 - val_classif_loss: 1.4060 - val_box_loss: 0.0151 - val_classif_accuracy: 0.4234 - val_box_accuracy: 0.6316\n",
            "Epoch 48/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.2704 - classif_loss: 0.2225 - box_loss: 0.0409 - classif_accuracy: 0.3973 - box_accuracy: 0.5928 - val_loss: 11.5557 - val_classif_loss: 1.4672 - val_box_loss: 0.0180 - val_classif_accuracy: 0.3431 - val_box_accuracy: 0.5789\n",
            "Epoch 49/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 1.8537 - classif_loss: 0.1809 - box_loss: 0.0369 - classif_accuracy: 0.4236 - box_accuracy: 0.5808 - val_loss: 10.7069 - val_classif_loss: 0.8478 - val_box_loss: 0.0170 - val_classif_accuracy: 0.3796 - val_box_accuracy: 0.6316\n",
            "Epoch 50/50\n",
            "167/167 [==============================] - 3s 19ms/sample - loss: 2.2705 - classif_loss: 0.2245 - box_loss: 0.0385 - classif_accuracy: 0.3845 - box_accuracy: 0.6048 - val_loss: 11.8509 - val_classif_loss: 1.0045 - val_box_loss: 0.0167 - val_classif_accuracy: 0.3577 - val_box_accuracy: 0.6842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4926d3d5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGrsSmiH78px",
        "colab_type": "code",
        "outputId": "597c0a71-3cb3-4483-e80e-cb2b2b1b9e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = model.predict(xtest, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r19/19 [==============================] - 1s 36ms/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh5_32us8IQ_",
        "colab_type": "code",
        "outputId": "3f62eb52-fce8-41eb-b616-29921730239b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "classifcation = [np.argmax(point) for point in data[0]]\n",
        "print(np.array(classifcation))\n",
        "\n",
        "print(classte)\n",
        "pont = data[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2 2 1 0 0 0 1 1 1 1 0 1 0 0 0 2 2 1]\n",
            "[2 0 2 1 0 0 0 1 1 1 1 0 0 0 0 0 2 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnokGKiHayjw",
        "colab_type": "code",
        "outputId": "23b0a184-84f0-4090-a36f-b42b0dc9baef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "for i in range(len(boxte)):\n",
        "    val = i\n",
        "    print(boxte[val], pont[val], np.sum(boxte[val] - pont[val]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.49339207 0.3215859  0.52422907 0.76651982] [0.52834046 0.45964617 0.6498769  0.4834122 ] -0.015548850733803299\n",
            "[0.50220264 0.40088106 0.3876652  0.9030837 ] [0.4201253  0.39148867 0.4645746  0.42862207] 0.48902194996237236\n",
            "[0.51101322 0.4845815  0.5154185  0.4185022 ] [0.5252442 0.4715331 0.6716939 0.5562092] -0.2951649754320473\n",
            "[0.50660793 0.43171806 0.44052863 0.44933921] [0.4324453  0.39485446 0.47036472 0.51487637] 0.015653003417447853\n",
            "[0.50660793 0.57268722 0.43612335 0.75770925] [0.5553866  0.50089115 0.52251863 0.63672596] 0.057605404423197004\n",
            "[0.49779736 0.51982379 0.5814978  0.85462555] [0.4789763 0.4342995 0.5052191 0.6731282] 0.3621213957339131\n",
            "[0.50220264 0.51982379 0.31718062 0.79295154] [0.501407   0.44765154 0.43081832 0.6068632 ] 0.14541850780600496\n",
            "[0.51101322 0.48017621 0.40088106 0.51982379] [0.4684146  0.42219645 0.43545607 0.53593874] 0.04988841351433476\n",
            "[0.5814978  0.49339207 0.78854626 0.7092511 ] [0.5485031  0.42431432 0.7211973  0.7013289 ] 0.17734362296595968\n",
            "[0.55506608 0.40088106 0.56387665 0.77973568] [0.52944    0.42763737 0.6093393  0.7097938 ] 0.023349014279075653\n",
            "[0.48017621 0.52422907 0.43171806 0.6123348 ] [0.43095228 0.41238937 0.43255112 0.5437979 ] 0.22876747523635493\n",
            "[0.49779736 0.42731278 0.66079295 0.77092511] [0.46377683 0.4137697  0.52760464 0.49375558] 0.45792145626660485\n",
            "[0.48898678 0.49779736 0.74449339 0.79735683] [0.5924465  0.508562   0.6090157  0.62370163] 0.19490849157787105\n",
            "[0.50220264 0.61674009 0.38325991 0.88105727] [0.58516806 0.54068357 0.53225696 0.68089134] 0.044259984850358314\n",
            "[0.51101322 0.50220264 0.5814978  0.74008811] [0.5212486  0.46641365 0.4509269  0.61629754] 0.2799150931940204\n",
            "[0.45814978 0.65638767 0.18061674 0.8061674 ] [0.53777176 0.5101982  0.546757   0.5820529 ] -0.07545822071083841\n",
            "[0.50660793 0.51101322 0.74449339 0.43171806] [0.40591872 0.3408358  0.53644073 0.32921672] 0.5814206232583471\n",
            "[0.59030837 0.42290749 0.49339207 0.55947137] [0.5465212  0.49076337 0.7288836  0.60492283] -0.30501171303215524\n",
            "[0.48898678 0.53303965 0.92070485 0.97356828] [0.65365213 0.5453444  0.87447655 0.8128838 ] 0.029942669269797162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIMjAGuAbvIx",
        "colab_type": "code",
        "outputId": "1c0e2a51-05b3-497f-f8dd-62a070933271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "trig = 6\n",
        "\n",
        "img = np.reshape(xtest[trig], (227,227))\n",
        "plt.imshow(img)\n",
        "\n",
        "box = pont[trig]\n",
        "\n",
        "h = int(box[2] * 227)\n",
        "w = int(box[3] * 227)\n",
        "xmid = int(box[0] * 227)\n",
        "ymid = int(box[1] * 227)\n",
        "\n",
        "ymax = int(ymid + h/2)\n",
        "ymin = int(ymid - h/2)\n",
        "\n",
        "xmax = int(xmid + w/2)\n",
        "xmin = int(xmid - w/2)\n",
        "\n",
        "cv2.rectangle(img,(xmin,ymax),(ymax,xmin),(0,255,0),3)\n",
        "\n",
        "plt.imshow(img)\n",
        "if classifcation[trig] == 0:\n",
        "    name = 'cucmber'\n",
        "elif classifcation[trig] == 1:\n",
        "    name = 'eggplant'\n",
        "elif classifcation[trig] == 2:\n",
        "    name = 'mushroom'\n",
        "\n",
        "print(name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cucmber\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqMzRSm4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Uci8Gvw_Szq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KFUZayDbVmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!kill process_id\n",
        "\n",
        "!ps -aux|grep python\n",
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV_QHaYWb-1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn't guaranteed\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}